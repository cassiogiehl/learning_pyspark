{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importando dependências"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iniciando conexão com spark (o parâmetro de localização do spark pode ser omitido)\n",
    "findspark.init('/usr/local/spark')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criando uma sessão do Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "        .master('local') \\\n",
    "        .appName('learning-spark') \\\n",
    "        .config('spark.executor.memory', '1gb') \\\n",
    "        .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lendo arquivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo os dados crús\n",
    "rdd = sc.textFile('CaliforniaHousing/cal_housing.data')\n",
    "\n",
    "# Definindo o cabeçalho\n",
    "header = sc.textFile('CaliforniaHousing/cal_housing.domain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['longitude: continuous.',\n",
       " 'latitude: continuous.',\n",
       " 'housingMedianAge: continuous. ',\n",
       " 'totalRooms: continuous. ',\n",
       " 'totalBedrooms: continuous. ',\n",
       " 'population: continuous. ',\n",
       " 'households: continuous. ',\n",
       " 'medianIncome: continuous. ',\n",
       " 'medianHouseValue: continuous. ']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Somente com o método .collect() o arquivo é lido\n",
    "header.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-122.230000,37.880000,41.000000,880.000000,129.000000,322.000000,126.000000,8.325200,452600.000000',\n",
       " '-122.220000,37.860000,21.000000,7099.000000,1106.000000,2401.000000,1138.000000,8.301400,358500.000000',\n",
       " '-122.240000,37.850000,52.000000,1467.000000,190.000000,496.000000,177.000000,7.257400,352100.000000',\n",
       " '-122.250000,37.850000,52.000000,1274.000000,235.000000,558.000000,219.000000,5.643100,341300.000000',\n",
       " '-122.250000,37.850000,52.000000,1627.000000,280.000000,565.000000,259.000000,3.846200,342200.000000']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Também podemos utilizao o .take(n), onde n = número de registros à serem lidos\n",
    "rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['-122.230000',\n",
       "  '37.880000',\n",
       "  '41.000000',\n",
       "  '880.000000',\n",
       "  '129.000000',\n",
       "  '322.000000',\n",
       "  '126.000000',\n",
       "  '8.325200',\n",
       "  '452600.000000'],\n",
       " ['-122.220000',\n",
       "  '37.860000',\n",
       "  '21.000000',\n",
       "  '7099.000000',\n",
       "  '1106.000000',\n",
       "  '2401.000000',\n",
       "  '1138.000000',\n",
       "  '8.301400',\n",
       "  '358500.000000']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dividindo os campos de cada linha\n",
    "rdd = rdd.map(lambda line: line.split(','))\n",
    "\n",
    "rdd.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-122.230000',\n",
       " '37.880000',\n",
       " '41.000000',\n",
       " '880.000000',\n",
       " '129.000000',\n",
       " '322.000000',\n",
       " '126.000000',\n",
       " '8.325200',\n",
       " '452600.000000']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recuperando a primeira linha\n",
    "rdd.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['-124.350000',\n",
       "  '40.540000',\n",
       "  '52.000000',\n",
       "  '1820.000000',\n",
       "  '300.000000',\n",
       "  '806.000000',\n",
       "  '270.000000',\n",
       "  '3.014700',\n",
       "  '94600.000000'],\n",
       " ['-124.300000',\n",
       "  '41.840000',\n",
       "  '17.000000',\n",
       "  '2677.000000',\n",
       "  '531.000000',\n",
       "  '1244.000000',\n",
       "  '456.000000',\n",
       "  '3.031300',\n",
       "  '103600.000000']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mesmo que .take(n)\n",
    "rdd.top(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convertendo RDD em DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando dependencia \n",
    "from pyspark.sql import Row\n",
    "\n",
    "# Mapeando o RDD para DataFrame\n",
    "df = rdd.map(lambda line: Row(longitude=line[0],\n",
    "                                 latitude=line[1],\n",
    "                                 housingMedianAge=line[2],\n",
    "                                 totalRooms=line[3],\n",
    "                                 totalBedrooms=line[4],\n",
    "                                 population=line[5],\n",
    "                                 households=line[6],\n",
    "                                 medianIncome=line[7],\n",
    "                                 medianHouseValue=line[8])).toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(longitude='-122.230000', latitude='37.880000', housingMedianAge='41.000000', totalRooms='880.000000', totalBedrooms='129.000000', population='322.000000', households='126.000000', medianIncome='8.325200', medianHouseValue='452600.000000'),\n",
       " Row(longitude='-122.220000', latitude='37.860000', housingMedianAge='21.000000', totalRooms='7099.000000', totalBedrooms='1106.000000', population='2401.000000', households='1138.000000', medianIncome='8.301400', medianHouseValue='358500.000000'),\n",
       " Row(longitude='-122.240000', latitude='37.850000', housingMedianAge='52.000000', totalRooms='1467.000000', totalBedrooms='190.000000', population='496.000000', households='177.000000', medianIncome='7.257400', medianHouseValue='352100.000000'),\n",
       " Row(longitude='-122.250000', latitude='37.850000', housingMedianAge='52.000000', totalRooms='1274.000000', totalBedrooms='235.000000', population='558.000000', households='219.000000', medianIncome='5.643100', medianHouseValue='341300.000000'),\n",
       " Row(longitude='-122.250000', latitude='37.850000', housingMedianAge='52.000000', totalRooms='1627.000000', totalBedrooms='280.000000', population='565.000000', households='259.000000', medianIncome='3.846200', medianHouseValue='342200.000000')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+----------------+-----------+-------------+-----------+-----------+------------+----------------+\n",
      "|  longitude| latitude|housingMedianAge| totalRooms|totalBedrooms| population| households|medianIncome|medianHouseValue|\n",
      "+-----------+---------+----------------+-----------+-------------+-----------+-----------+------------+----------------+\n",
      "|-122.230000|37.880000|       41.000000| 880.000000|   129.000000| 322.000000| 126.000000|    8.325200|   452600.000000|\n",
      "|-122.220000|37.860000|       21.000000|7099.000000|  1106.000000|2401.000000|1138.000000|    8.301400|   358500.000000|\n",
      "|-122.240000|37.850000|       52.000000|1467.000000|   190.000000| 496.000000| 177.000000|    7.257400|   352100.000000|\n",
      "+-----------+---------+----------------+-----------+-------------+-----------+-----------+------------+----------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(longitude='-122.230000', latitude='37.880000', housingMedianAge='41.000000', totalRooms='880.000000', totalBedrooms='129.000000', population='322.000000', households='126.000000', medianIncome='8.325200', medianHouseValue='452600.000000')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['longitude',\n",
       " 'latitude',\n",
       " 'housingMedianAge',\n",
       " 'totalRooms',\n",
       " 'totalBedrooms',\n",
       " 'population',\n",
       " 'households',\n",
       " 'medianIncome',\n",
       " 'medianHouseValue']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Colunas\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- longitude: string (nullable = true)\n",
      " |-- latitude: string (nullable = true)\n",
      " |-- housingMedianAge: string (nullable = true)\n",
      " |-- totalRooms: string (nullable = true)\n",
      " |-- totalBedrooms: string (nullable = true)\n",
      " |-- population: string (nullable = true)\n",
      " |-- households: string (nullable = true)\n",
      " |-- medianIncome: string (nullable = true)\n",
      " |-- medianHouseValue: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Schema\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertendo dados em float para melhorara o desempenho do DataFrame\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "df = df.withColumn('longitude', df['longitude'].cast(FloatType())) \\\n",
    "        .withColumn('latitude', df['latitude'].cast(FloatType())) \\\n",
    "        .withColumn('housingMedianAge', df['housingMedianAge'].cast(FloatType())) \\\n",
    "        .withColumn('totalRooms', df['totalRooms'].cast(FloatType())) \\\n",
    "        .withColumn('totalBedrooms', df['totalBedrooms'].cast(FloatType())) \\\n",
    "        .withColumn('population', df['population'].cast(FloatType())) \\\n",
    "        .withColumn('households', df['households'].cast(FloatType())) \\\n",
    "        .withColumn('medianIncome', df['medianIncome'].cast(FloatType())) \\\n",
    "        .withColumn('medianHouseValue', df['medianHouseValue'].cast(FloatType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertendo dados em float com uma função\n",
    "def convertColumnsToFloat(df, columns):\n",
    "    for col in columns:\n",
    "        df = df.withColumn(col, df[col].cast(FloatType()))\n",
    "    return df\n",
    "\n",
    "# Converter todas as colunas\n",
    "columns_to_convert = df.columns\n",
    "\n",
    "# Aplicando a função\n",
    "df = convertColumnsToFloat(df, columns_to_convert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- longitude: float (nullable = true)\n",
      " |-- latitude: float (nullable = true)\n",
      " |-- housingMedianAge: float (nullable = true)\n",
      " |-- totalRooms: float (nullable = true)\n",
      " |-- totalBedrooms: float (nullable = true)\n",
      " |-- population: float (nullable = true)\n",
      " |-- households: float (nullable = true)\n",
      " |-- medianIncome: float (nullable = true)\n",
      " |-- medianHouseValue: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+\n",
      "|population|totalBedrooms|\n",
      "+----------+-------------+\n",
      "|     322.0|        129.0|\n",
      "|    2401.0|       1106.0|\n",
      "|     496.0|        190.0|\n",
      "|     558.0|        235.0|\n",
      "|     565.0|        280.0|\n",
      "|     413.0|        213.0|\n",
      "|    1094.0|        489.0|\n",
      "|    1157.0|        687.0|\n",
      "|    1206.0|        665.0|\n",
      "|    1551.0|        707.0|\n",
      "+----------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Selecionando collunas\n",
    "df.select('population', 'totalBedrooms').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----+\n",
      "|housingMedianAge|count|\n",
      "+----------------+-----+\n",
      "|            52.0| 1273|\n",
      "|            51.0|   48|\n",
      "|            50.0|  136|\n",
      "|            49.0|  134|\n",
      "|            48.0|  177|\n",
      "|            47.0|  198|\n",
      "|            46.0|  245|\n",
      "|            45.0|  294|\n",
      "|            44.0|  356|\n",
      "|            43.0|  353|\n",
      "|            42.0|  368|\n",
      "|            41.0|  296|\n",
      "|            40.0|  304|\n",
      "|            39.0|  369|\n",
      "|            38.0|  394|\n",
      "|            37.0|  537|\n",
      "|            36.0|  862|\n",
      "|            35.0|  824|\n",
      "|            34.0|  689|\n",
      "|            33.0|  615|\n",
      "+----------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('housingMedianAge').count().sort('housingMedianAge', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+-----------------+------------------+------------------+-----------------+------------------+-----------------+------------------+------------------+\n",
      "|summary|          longitude|         latitude|  housingMedianAge|        totalRooms|    totalBedrooms|        population|       households|      medianIncome|  medianHouseValue|\n",
      "+-------+-------------------+-----------------+------------------+------------------+-----------------+------------------+-----------------+------------------+------------------+\n",
      "|  count|              20640|            20640|             20640|             20640|            20640|             20640|            20640|             20640|             20640|\n",
      "|   mean|-119.56970444871473|35.63186143109965|28.639486434108527|2635.7630813953488|537.8980135658915|1425.4767441860465|499.5396802325581|3.8706710030346416|206855.81690891474|\n",
      "| stddev|  2.003531742932898|2.135952380602968| 12.58555761211163|2181.6152515827944| 421.247905943133|  1132.46212176534|382.3297528316098|1.8998217183639696|115395.61587441359|\n",
      "|    min|            -124.35|            32.54|               1.0|               2.0|              1.0|               3.0|              1.0|            0.4999|           14999.0|\n",
      "|    max|            -114.31|            41.95|              52.0|           39320.0|           6445.0|           35682.0|           6082.0|           15.0001|          500001.0|\n",
      "+-------+-------------------+-----------------+------------------+------------------+-----------------+------------------+-----------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pré-processamento dos valores alvo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(longitude=-122.2300033569336, latitude=37.880001068115234, housingMedianAge=41.0, totalRooms=880.0, totalBedrooms=129.0, population=322.0, households=126.0, medianIncome=8.325200080871582, medianHouseValue=4.526),\n",
       " Row(longitude=-122.22000122070312, latitude=37.86000061035156, housingMedianAge=21.0, totalRooms=7099.0, totalBedrooms=1106.0, population=2401.0, households=1138.0, medianIncome=8.301400184631348, medianHouseValue=3.585)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A variável dependente deve ser normalizada\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "df = df.withColumn('medianHouseValue', col('medianHouseValue')/100000)\n",
    "\n",
    "df.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Engenharia de Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+----------------+----------+-------------+----------+----------+------------+----------------+-----------------+----------------------+-------------------+\n",
      "|longitude|latitude|housingMedianAge|totalRooms|totalBedrooms|population|households|medianIncome|medianHouseValue|roomsPerHousehold|populationPerHousehold|    bedroomsPerRoom|\n",
      "+---------+--------+----------------+----------+-------------+----------+----------+------------+----------------+-----------------+----------------------+-------------------+\n",
      "|  -122.23|   37.88|            41.0|     880.0|        129.0|     322.0|     126.0|      8.3252|           4.526|6.984126984126984|    2.5555555555555554|0.14659090909090908|\n",
      "|  -122.22|   37.86|            21.0|    7099.0|       1106.0|    2401.0|    1138.0|      8.3014|           3.585|6.238137082601054|     2.109841827768014|0.15579659106916466|\n",
      "+---------+--------+----------------+----------+-------------+----------+----------+------------+----------------+-----------------+----------------------+-------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# # Dividindo o total de quartos pela quantidade de domicílios por grupo de blocos\n",
    "# roomsPerHousehold = df.select(col('totalRooms')/col('households'))\n",
    "\n",
    "# # Dividindo a população total por grupo de blocos pela quantidade de pessoas na familia\n",
    "# populationPerHousehold = df.select(col('population')/col('households'))\n",
    "\n",
    "# # Dividindo o total de quartos com cama pelo total de cômodos\n",
    "# bedroomsPerRoom = df.select(col('totalBedRooms')/col('totalRooms'))\n",
    "\n",
    "df = df.withColumn(\"roomsPerHousehold\", col(\"totalRooms\")/col(\"households\")) \\\n",
    "   .withColumn(\"populationPerHousehold\", col(\"population\")/col(\"households\")) \\\n",
    "   .withColumn(\"bedroomsPerRoom\", col(\"totalBedRooms\")/col(\"totalRooms\"))\n",
    "\n",
    "df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------+----------+----------+------------+-----------------+----------------------+-------------------+\n",
      "|medianHouseValue|totalBedRooms|population|households|medianIncome|roomsPerHousehold|populationPerHousehold|    bedroomsPerRoom|\n",
      "+----------------+-------------+----------+----------+------------+-----------------+----------------------+-------------------+\n",
      "|           4.526|        129.0|     322.0|     126.0|      8.3252|6.984126984126984|    2.5555555555555554|0.14659090909090908|\n",
      "|           3.585|       1106.0|    2401.0|    1138.0|      8.3014|6.238137082601054|     2.109841827768014|0.15579659106916466|\n",
      "|           3.521|        190.0|     496.0|     177.0|      7.2574|8.288135593220339|    2.8022598870056497|0.12951601908657123|\n",
      "+----------------+-------------+----------+----------+------------+-----------------+----------------------+-------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Reordenando a ordem das colunas e retirando colunas indesejadas. A variável alvo ficará em primeiro para que não seja afetadan a padronização\n",
    "df = df.select(\"medianHouseValue\", \n",
    "              \"totalBedRooms\", \n",
    "              \"population\", \n",
    "              \"households\", \n",
    "              \"medianIncome\", \n",
    "              \"roomsPerHousehold\", \n",
    "              \"populationPerHousehold\", \n",
    "              \"bedroomsPerRoom\")\n",
    "\n",
    "df.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Padronização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import DenseVector\n",
    "\n",
    "input_data = df.rdd.map(lambda x: (x[0], DenseVector(x[1:])))\n",
    "df = spark.createDataFrame(input_data, ['label', 'features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|4.526|[129.0,322.0,126....|\n",
      "|3.585|[1106.0,2401.0,11...|\n",
      "|3.521|[190.0,496.0,177....|\n",
      "+-----+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(label=4.526, features=DenseVector([129.0, 322.0, 126.0, 8.3252, 6.9841, 2.5556, 0.1466]), features_scaled=DenseVector([0.3062, 0.2843, 0.3296, 4.3821, 2.8228, 0.2461, 2.5264])),\n",
       " Row(label=3.585, features=DenseVector([1106.0, 2401.0, 1138.0, 8.3014, 6.2381, 2.1098, 0.1558]), features_scaled=DenseVector([2.6255, 2.1202, 2.9765, 4.3696, 2.5213, 0.2031, 2.6851]))]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.feature import StandardScaler\n",
    "\n",
    "standardScaler = StandardScaler(inputCol=\"features\", outputCol=\"features_scaled\")\n",
    "\n",
    "scaler = standardScaler.fit(df)\n",
    "\n",
    "scaled_df = scaler.transform(df)\n",
    "\n",
    "scaled_df.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = scaled_df.randomSplit([.8,.2],seed=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "model = LinearRegression(labelCol='label', maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "\n",
    "linear_model = model.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1.4542345782162025, 0.14999),\n",
       " (1.6495895629633672, 0.175),\n",
       " (1.482098957606102, 0.332),\n",
       " (1.6123448501897313, 0.346),\n",
       " (1.6541552239238302, 0.35)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = linear_model.transform(test_data)\n",
    "\n",
    "predictions = predicted.select(\"prediction\").rdd.map(lambda x: x[0])\n",
    "labels = predicted.select('label').rdd.map(lambda x: x[0])\n",
    "\n",
    "predictionAndLabel = predictions.zip(labels).collect()\n",
    "predictionAndLabel[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([0.0, 0.0, 0.0, 0.2767, 0.0, 0.0, 0.0])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model.coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9947076240544817"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model.intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4192463677898063"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model.summary.rootMeanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4192463677898063"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model.summary.r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parar a execução do spark\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
